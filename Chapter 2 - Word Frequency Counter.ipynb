{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "Write a program that downloads a web page requested by the user and reports up to ten most frequently used words. The program should treat all words as case-insensitive. For the purpose of this exercise, assume that a word is described by the regular expression r\"\\w+\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import re\n",
    "from collections import Counter\n",
    "import urllib.request\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The web 'https://en.wikipedia.org/wiki/Seattle' has been opened and saved on the 'html' object.\n"
     ]
    }
   ],
   "source": [
    "# Getting info from the Web\n",
    "url = \"https://en.wikipedia.org/wiki/Seattle\"\n",
    "\n",
    "try:\n",
    "    with urllib.request.urlopen(url) as webdoc:\n",
    "        html = webdoc.read()\n",
    "        print (\"The web %r has been opened and saved on the 'html' object.\" % url)\n",
    "except:\n",
    "    print (\"The web %r could'n be opened.\" % url, file = sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Text start: 6366 \n",
      " Text end: 675247\n"
     ]
    }
   ],
   "source": [
    "# Extract the text from the web document\n",
    "text_start = html.find(b\"<body\")\n",
    "text_end = html.find(b\"/body>\")\n",
    "print (\" Text start: %r \\n Text end: %r\" % (text_start, text_end))\n",
    "html = html[text_start:text_end] # New document to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "html_text = re.findall(b\"\\w+\", html, re.I) # Extract the words without html tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b'a', 5727),\n",
       " (b'span', 3756),\n",
       " (b'class', 3337),\n",
       " (b'href', 2743),\n",
       " (b'amp', 2189),\n",
       " (b'title', 2091),\n",
       " (b'li', 1902),\n",
       " (b'wiki', 1668),\n",
       " (b'Seattle', 1355),\n",
       " (b'rft', 1177)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the 10 most common words\n",
    "word_counter = Counter(html_text)\n",
    "word_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
